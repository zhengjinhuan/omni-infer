[build-system]
requires = ["setuptools>=64", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "omni_infer"
version = "0.4.0"
description = "Omni_Infer is a powerful suite of inference accelerators tailored for the Ascend NPU platform, fully compatible with vLLM, and designed to deliver high-performance, enterprise-grade inference with native support and a growing feature set."
authors = [
    { name="Huawei" }
]
requires-python = ">=3.10"
dependencies = [
    "ansible>=8.0",
    "pyyaml>=6.0",
    "chardet",
]

[project.scripts]
omni_cli = "omni.cli.main:main"

[project.entry-points."vllm.platform_plugins"]
npu = "omni.adaptors.vllm.platform:register"

[project.entry-points."vllm.general_plugins"]
npu_optimized_models = "omni.models:register_model"
kv_connectors = "omni.accelerators.pd:register"
tool_parsers = "omni.adaptors.vllm.entrypoints.openai.tool_parsers:register_tool"
reasoning = "omni.adaptors.vllm.reasoning:register_reasoning"

[tool.setuptools.packages.find]
include = ["omni*"]